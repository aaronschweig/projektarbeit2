\documentclass[
	12pt,
	BCOR=5mm,
	DIV=12,
	headinclude=on,
	footinclude=off,
	parskip=half,
	bibliography=totoc,
	listof=entryprefix,
	toc=listof,
	numbers=noenddot,
	plainfootsepline
]{scrreprt}

%	Konfigurationsdatei einziehen
\input{config}

\begin{document}

\TitelDerArbeit{TODO}
\AutorDerArbeit{Aaron Schweig}
\Firma{Hays AG}
\Kurs{WWI18SEC}

\input{titlepage}

\pagenumbering{roman} % Römische Seitennummerierung
\normalfont

%	Kurzfassung
\input{abstract}

%	Inhaltsverzeichnis
\tableofcontents

%	Abbildungsverzeichnis
\listoffigures

%	Tabellenverzeichnis
% \listoftables

% 	Abkürzungsverzeichnis (siehe Datei acronyms.tex!)
\input{acronyms}
\ohead{Acronyms} % Neue Header-Definition

%--------------------------------
% Start des Textteils der Arbeit
%--------------------------------
\clearpage
\ihead{\chaptername~\thechapter}
\ohead{\headmark}
\pagenumbering{arabic}

Outline:
\begin{itemize}
	\item Einleitung schreiben, wieso das Thema wichtig ist und wieso die Schnittstelle so relevant ist
	\begin{itemize}
		\item kurzes Aufzeigen des Problems und Hintergrundes der Arbeit
	\end{itemize}
	\item Kurz die Historie von Microservices erklären
	\begin{itemize}
		\item von Monolithen über SOA bis hin zu Microservices
		\item Anhand eines versimplifizierten beispiels aufzeigen wie Zielarchitekturen aussehen
	\end{itemize}
	\item Def. Microservice, Governance und Observability raushauen
	\begin{itemize}
		\item Dabei auf die verschiedenen Säulen der Observability achten
		\item Wichtigstens Aspekte bei Governance noch einmal herausstellen
		\item Eigentliche Pros der Microservice-Def unter den Gesichtspunkten der G\&O evlt nicht mehr so gut
	\end{itemize}
	\item Wo liegt überhaupt das Problem (nochmal aus Einleitung aufgreifen), Herausarbeiten, evtl. ja schon passiert?
	\item Herausarbeiten von Kriterien für ein Tool im Schnittstellenbereich zwischen G\&O
	\item Wie sehen potenzielle Lösungen unter Berücksichtigung der auf Basis des Problems hergeleiteten Kriterien aus?
	\begin{itemize}
		\item Eine Idee von Elastic vorstellen $\Rightarrow$ APM zusammen mit ML-Nodes können zur Anomaly-Detection und Predicitve Maintance genutzt werden. Lösen die das eigentliche Problem, wenn ja in welchem Ausmaß
		\item Kurze Einführung in Graphdatenbanken, im speziellen Neo4J. Wieso passen die so gut? referenzieren auf Bilder und \enquote{Abhängigkeiten} Wie kann damit eine Lösung konstruiert werden?
		\begin{itemize}
			\item Statischer Ansatz $\Rightarrow$ von den Entwicklern definierte Abhängigkeiten werden in der Service-Definition angegeben. Der Graph kann aus diesen SD's erstellt werden. Hier gibt es Probleme: Manuelle Veranwtortlichkeit widerspricht eigentlicher Idee von Risikoeinschätzung, da ein neuer Fehler Mensch eingebaut wird.
			\item Automatischer Nutzungsbasierter, somit dynamischer Aufbau des Graphen. Prinzip ähnlich wie bei Prometheus (populäres Tool zum sammeln von Metriken). Konzept ähnlich wie Distributed Tracing. Dort werden alle Traces mit ihren Spans zusammengefasst und zentral ausgewertet. Kombination aus dieser Idee mit Prometheus-Ansatz sieht dann folgendermaßen aus:
			
			Jeder Service exposed einen \texttt{/traffic}-Endpoint der unstrukturierte Daten bzgl. der Netzwerkaktivität enthält. Diese können dann in einem Service der für den Aufbau des Graphen zuständig ist zu ebendiesem umgewandelt werden.
			\item Es kann zusätzlich überlegt werden, ob anstatt dieses \texttt{PULL}-Verfahrens eine Push Variante gewählt wird, welche ähnlich wie \texttt{fluentd} als Sidecar in einer Containererisierten Umgebung läuft. Die könnte dann periodisch die Netzwerkdaten pushen, wenn sie Zugriff darauf hat.
		\end{itemize}
		\item Es kann überlegt werden welche Metadaten zusätzlich im Rahmen dieses Graphen eine sinnvolle Ergänzugn bieten würden, sodass ein weiterer Mehrwert geschaffen werden kann. (Ist das noch im Rahmen der Arbeit? Kommt das eher in den Ausbilck mit ein paar Ideen?)
	\end{itemize}
	\item Wie können jetzt die Sachen in dem coolen Graphen genutzt werden?
	\begin{itemize}
		\item Kurze \texttt{CYPHER-QUERIES} Aufschreiben:
		\begin{itemize}
			\item Wie finde ich affectete services raus
			\item was passiert wenn ein Service X ausfällt
			\item Was ist die Zentralste Komponente in meinem Unternehmen
			\item usw.
		\end{itemize}
	\end{itemize}
\end{itemize}

Fragen:
\begin{itemize}
	\item Muss ich erklären was ein Graph ist und wie er funktioniert?
	\item Wie kann ich \textbackslash autocite die fußnoten reusen
\end{itemize}

\chapter{Einleitung}

% CHAPTER: Microservice - Observability - Governance
\input{chapters/microservice_observability_gouvernance.tex}

\section{Eine Lücke zwischen Governance und Observability}

Im vorherigen Abschnitt wurden einige potenzielle Problempunkte beim Nutzen einer Microservicearchitektur identifiziert. Es sticht vor allem heraus, dass es für einen Verantwortlichen nur sehr schwer möglich ist fundierte Risikoeinschätzungen abzugeben. Es stellt sich im unternehmerischen Alltag oftmals die Frage, wer einen Fehler im System beheben muss. Diese Frage kann genau dann beantwortet werden, wenn klar ist wo der Fehler liegt. Im Abschnitt über Observability sind mithilfe der drei Säulen Möglichkeiten geschaffen einen fehlerhaften Service zu finden. Trotzdem kann auch mithilfe dieser Informationen nicht unbedingt immer die Ursache des Fehlers ausfindig gemacht werden. Ein sehr häufiges Ergebnis bei der Fehleranalyse im Kontext verteilter Systeme ist, dass mehr als ein Service als Fehlerursache in Frage kommt. Das bedeutet, dass der zuständige Mitarbeiter für die Fehleridentifizierung mit mehreren Teams in Kontakt treten muss und diese dann den Fehler in ihren Services so schnell wie möglich beheben können. \\
Auch und vor allem bei Fehlern in einer Software als Kernbestandteil eines Unternehmens greift eine altbekannte Redensart: \textit{Zeit ist Geld}. Dass Zeit wirklich Geld bedeuetet und die Zeit, die bis zum beheben eines Fehlers vergeht so kurz wie möglich gehalten werden muss zeigen Zahlen eines Ausfalls der Amazon Website aus dem Jahr 2016. Dort führte eine Nichterreichbarkeit der Website für nur 20 Minuten zu einem Verlust von ca 3.5 Mio Euro \marginpar{QUELLE}.

An dieser Stelle, einer Schnittstelle zwischen Governance und Observability gilt es so wenig Zeit wie möglich zu verschwenden, um mehr Zeit bei der eigentlichen Fehlerbehebung zur Verfügung zu haben. Es sollte also innerhalb eines Unternehmens eine Möglichkeit geben diese Informationen schnell aufzufinden. Im folgenden werdene einige Anforderungen herausgestellt, welches ein Tools haben muss, um in diesem Schnittstellenbereich einen positiven Einfluss auf die Fehlerbehebung zu haben.

\section{Anforderungen an das Konzept}\label{chap:Anforderungen}

Ein Tool, das sich in diese Lücke einfügt benötigt sowohl Komponenten aus dem eher der Governance zuzuschreibenden Bereich, als auch Elemente aus der Observability.

\begin{enumerate}

\item \textbf{\enquote{Zeit ist Geld}:}\\
Im vorherigen Kapitel wurde diese Redensart bereits genutzt, um einen wichtige Anforderung zu verdeutlichen. Die Geschwindigkeit, in der ein Fehler innerhalb von Software identifiziert und behoben werden kann ist maßgeblich entscheidend für die Auswirkungen und die Tragweite des Fehlers. Die Auswirkungen sind nicht immer nur finazieller Natur. Auch im Falle von Sicherheitslücken in einem System gilt es den Ursprung eines Angriffs schnellstmöglich identifizieren zu können, um auch hier den Schaden möglichst gering zu halten. Wird also ein Tool entwickelt, dass in einem solchen Fall zur Anwendungen kommt muss es dem Endnutzer eine einfache, schnelle Möglichkeit bieten, die Ursache eines Fehlers unter hunderten möglichen Services zu finden. \\
Das Finden des Services leitet auch direkt zum nächsten elementaren Bestandteil eines solchen Tools über.

\item \textbf{Bereitstellen von Informationen - nicht nur generieren von Daten:}\\
Ein solches Tool hat auch die Aufgabe, generierte Daten, seien es spezielle, extra gesammelte, oder bereits vorhande durch andere Tools zur Verfügung gestellte Daten so aufzubereiten, dass nutzbare Informationen daraus entstehen. Diese vorhandenen Informationen müssen fundiert und verlässlich sein, sodass auch unter Zeitdruck eine richtige Entscheidung für das weitere vorgehen getroffen werden kann. Hierbei kommt es nicht nur darauf an, Informationen für \textit{aktuelle} Entscheidungen bereitzustellen, sondern auch, aus vorhandenen Daten und Informationen vorhersagen generieren zu können, um im Fehlerfall nicht erst auf die Interaktion eines Endnutzers warten zu müssen, der einen Fehler identifizieren will, sondern um direkt proaktiv auf einen Nutzer zuzugehen mit der Information, dass ein Fehler vorleigt und wo die wahrscheinliche Ursache dafür liegt. Dazu können Ideen, aus der \textbf{Predictive Maintance} oder der \textbf{Anomaly Detection} genutzt werden.

\item \textbf{Einhaltung von Standards:}\\
Um die für diese Anforderungen notwendigen Informationen generieren zu können sind Rohdaten notwendig. Diese Rohdaten können, wie bereits erwähnt eigens für dieses Tool generiert werden, oder es können Daten, die von anderen Tools generiert werden verarbeitet werden. Damit dies möglich ist, muss klar sein, in welche Format die Daten aus \enquote{fremden} Tools vorhanden sind. Dies kann unter Umständen von Anbieter zu Anbieter unterschiedlich sein. Deshalb sollte ein neu entwickeltes Tools, um Kompatibilität mit anderen Tools zu erhalten, offenen und weit verarbeiten Standards folgen. Dies ermöglicht nicht nur ein erhöhtes Anwendungspotenzial, sonder erleichtert auch die Arbeit in der Entwicklung, da nur wenige Schnittstellen bereitgestellt werden müssen und eine hohe Anzahl an möglichen Kombinationen möglich ist.

\item \textbf{Kaum manueller Aufwand zur Integration und Wartung:}\\
Ein solches Tool wird mit hoher Wahrscheinlichkeit aus mehreren Komponenten bestehen. Eine Komponente wird als Zentrale fungieren, um Daten jeglichen Ursprungs entgegenzunehmen und auszuwerten. Eine andere Komponente kann beispielsweise in einem einzelnen Service verarbeitet werden, um Daten zu generieren. Bei der Einführung eines solchen Tools sollte es mit möglichst wenig manuellem Aufwand möglich sein, den vollen Funktionsumfang zu nutzen. Des weiteren sollte auch im laufenden Betrieb keine bis kaum manuelle Wartung nötig sein. Denn je komplexer die Integration eines solchen Tools ist, desto mehr Fehler können nur durch die Einführung oder Wartung injeziert werden. Die Fehlerquelle Mensch sollte möglichst elimiert werden können.

\item \textbf{dezentrale Governance:}\\
Ein neues Tool sollte die Grundelgende Dezentralität einer Microservicearchitektur unterstützen. Es muss sichergestellt werden, dass Zusammenhänge einfach und klar visualisiert werden können, damit Nutzer auch hier einen Mehrwert erzielen können.

\end{enumerate}

Diese Anforderungen stellen wichtige Elemente dar, um den Nutzen eines solchen Tools evaluieren zu können. Bevor nun das eigentliche Konzept erläutert werden, wird überprüft, inwiefern eine Lösung mit bereits bestehenden Tools konstruiert werden kann. Dazu werden die oben definierten Kriterien genutzt, um einen Vergleich durchführen zu können. Dieser Vergleich wird mithilfe einer \marginpar{Heißt das BalancedScoreCard} XX durchgeführt.

% \section{Verschiedene Ansätze zum lösen von Governance und Observability}
% \subsection{Ansätze verschiedener Unternehmen}
% \begin{itemize}
% 	\item Elastic
% 	\item Neo4J
% \end{itemize}
% Microservice Governance und Themen der Observability sind bekannte Probleme und wurden schon oft von verschiedenen Organsiationen gelöst. Bewegt man sich im OpenSource bereich so findet sich mit der \ac{CNCF} ein Zusammenschluss, welcher versucht offene Standards für viele elementare Bereiche der Observability und der Governance zu erreichen.

% \section{Auf Basis der kriterien hergeleiteter eigener Ansatz mithilfe eines MicroserviceGraphen}

% Innerhalb der Softwareentwicklung stellen sich die oben beschriebenen Probleme oftmals in ähnlicher Form dar. Ein praktisches Beispiel kommt aus dem Bereich der Webentiwcklung, in welchem Bundler ein ähnliches Problem zu bekämpfen haben. Diese besitzen zur Aufgabe Code, welcher in verschiedenen Dateien verteilt ist so zusammenzuführen, das später eine einzige syntaktisch korrete und ausführbare Datei vorliegt. Dabei muss allerdings bedacht werden, dass verschiedene Dateien unterschiedliche Codesegmente aus anderen Dateien importieren können und wiederum eigene Funktionen oder Variablen exportieren können. Dabei zählt es zu den Aufgaben eines Bundlers sicherzustellen, dass ein für die Programmiersprace valider Kontrollflow entsteht. Um dieses Problem zu lösen nutzen Bundler die Möglichkeit, einen Dependency-Graphen auf Basis der Imports und Exports aufzustellen. Dieser wird dann genutzt, um anhand des Startpunktes des Graphen die Zusammenführung der Dateien zu beginnen. Dabei müssen zusätzlich noch weitere Problem gelöst werden, da innerhaln eines Graphen auch circuläre Abhängigkeiten entstehen können, welche aufgelöst werden müssen. Ein Beispiel einer Zirkulären Abhängigkeit kann der \autoref{fig:GraphViz} entnommen werden.

% \begin{itemize}
% 	\item Man es während CI/CD Stuff machen. Auch part von Microservices.
% 	\item Man kann es danach dynamisch nach Usage discovern lassen.
% 	\item Man kann einen kombinierten Ansatz wählen, um sowohl initial den Service inklusikve Metadaten sehen und danach die Nutzung ähnlich wie im Epsagon Dashboard zu sehen
% \end{itemize}

% \begin{figure}[h]
% 	\centering
% 	\makebox[\textwidth]{\includegraphics[width=\linewidth]{img/dependency-graph.png}}
% 	\caption[Dependency Graph]{Visulaisierung eines Dependency-Graphen mit zirkulären Abhängigkeiten. Quelle: \cite[]{GraphViz}}
% 	\label{fig:GraphViz}
% \end{figure}
%  All diese Elemente dienen als Grundlage zu der Idee, dass zur Risikoeinschätzung der Auswirkungen eines Fehelerfalls innerhalb einer Microservicearchitektur ein ähnlicher Dependency-Graph eine große Hilfe darstellen würde. Baut man den Graphen so auf, wie in obiger Analogie beschrieben, so erhält man einen Graphen, welcher Anzeigt ob und wie weit bestimmte Microservices miteinenander kommunizieren oder sogar voneinander Abhängigkeit sind. Dies beitet die Möglichkeit wertvolle Einblicke in das \textit{makroskopische} Zusammenspiel der einzelnen Komponenten einer Architektur zu erhalten. Ein Softwarearchitekt hat nun die Möglichkeit bei der Entscheidung über die Einführung eines neuen Service Informationen aus ebendiesem Graphen zu nutzen, um festzustellen ob eine zu Starke Abhängikteit zwischen Services vorhanden ist, oder ob es bei der Entwicklung bereits bestehende Abhängigkeiten gibt.
% Der beschriebene Graph kann also als eine Art Service-Registry angesehen werden, welche Informationen zu der Beziehung zwischen verschiedenen Services beinhaltet. Gleichzeitig wird dadurch vor allem der Bereich der Microservice-Governance betreten, wo eine Service-Registry eine zentrale Komponente darstellt. 

% Zusammenfassend lässt sich das Konzept also folgendermaßen beschreiben: \\
% Eine Schnittstelle zwischen Microservice-Governance und -Observability wird mithilfe eines Dependency-Graphen gebildet. So spielen Aspekte einer Service-Registry und Elemente des Distributed-Tracing eine große Rolle in diesem Ansatz.

\chapter{Konzeption einer graphbasierten Serviceregistry}

Im folgenden Kapitel wird versucht auf Basis der in \vref{chap:Anforderungen} beschriebenen Anforderungen ein Konzept für ein Tool zu erarbeiten, welches als \enquote{intelligente} Service-Registry fungiert. Dazu wird zunächst die eine mögliche Technologiewahl erläutert. Danach werden noch einige möglichen Funktionenen mithilfe von Beispielen vorgestellt.

\section{Wieso wird ein Graph verwendet?}

Das Fundament des vorgeschlagenen Konzept bildet die Abbildung der Services und deren Zusammenhänge in einem Graphen. Ähnlich, wie Microservices danach bestrebt sind, die bestmögliche Technologie für die Anforderung zu wählen, muss auch für ein neues Tool, eine passende Technologie gefunden werden. Um zu verstehen, wieso eine graphbasierte Darstellung für den Anwedungfall gut geeignet ist, soll ein Graph und Graphdatenbanken definiert werden.

\begin{definition}[gerichteter Graph]\autocite[Kapitel 1.2]{Bang-Jensen2007}
	Ein gerichteter Graph ist ein geordnetes Tupel $$G = (V,A)$$ für das gilt:
	\begin{itemize}
		\item $V(G)$ ist eine nichtleere Menge, deren Elemente man Knoten (engl. \textit{verticies}) nennt
		\item und einer endlichen Menge $A(G) \subseteq V \times V$ von geoordneten Tupeln verschiedener Knoten, die man Kanten (engl. \textit{arcs}) nennt.
	\end{itemize}

	Bei einem gerichteten Graphen handelt es sich um ein \textbf{geordnetes Tupel} $v \in A$, wobei die \enquote{Richtung} vorgegeben ist durch die Reihenfolge im Tupel. Bei einem ungerichtetetn Graphen besteht $A$ aus einer Menge \textbf{ungeordneter Tupel}.
\end{definition}

Diese mathematische Definition beschreibt eine interessante Datenstruktur für die Informatik und die Softwareentwicklung. Diese Datenstruktur versucht also die vorgegebenen Eigenschaften eines Graphen wie in der graphentheorie Beschrieben zu realisieren. \\
Eine Unterkategorie bei den gerichteten Graphen sind sowohl zyklische, als auch azyklische gerichtete Graphen. Dabei handelt es sich um Repräsentaten eines gerichteten Graphen, welche keinen gerichteten Kreis enthalten. Betrachtet man nun den Anwedungsfall des zu konzeptionierenden Tools, so stellt man fest, dass ein azyklischer Graph nicht die richtige Wahl wäre. Dies sollim foglenden erläutert werden.

\begin{example}
	Beginnen wir mit der formalen Defitionen des Graphen, welcher die Beziehung zwischen Microservices abbilden soll. Der Graph $G$ besteht dann also aus: 
	\begin{itemize}
		\item der Menge $V(G)=\text{Menge aller Services in einem Unternehmen}$
		\item der Menge $A(G)=\{a,b \mid \text{a benötigt Informationen aus b}\}$
	\end{itemize}
	Der Graph beinhaltet also Informationen über einen Service, als auch über seine Verbindungen mit anderen Services. Da es ein gerichteter Graph ist gilt für $$(a,b), (b,a) \in A(G),\text{ dass }(a,b) \neq (b,a),$$ da es sich bei den Elementen von $A(G)$ um geordnete Tupel handelt. Diese Tatsache spiegelt sich auch in der Relatiät wieder da die Abhängigkeit eines Services $a$ von einem Service $b$ nicht dieselbe Anfrage wiederspiegelt, die Service $b$ von Service $a$ hat.
\end{example}

Man erkennt also bereits jetzt, dass rein mit dem mathematischen Modell eines Graphen bereits viele realen Aspekte übereinstimmen, was es als potenzielles Datenmodell qualifiziert. Die Datenstruktur eines Graphen hat zusätzlich noch die Möglichkeit Informationen sowohl an den Knoten, als auch an den Kanten zu speichern \footnote{TODO: Quelle}. Zusätzlich könnte eine weitere Idee aus der \textbf{Graphentheorie} eine nützliche Ergänzung zu der bisherigen Idee darstellen.

\begin{definition}[Fluss]
	In der Graphentheorie stellt ein Fluss eine Funktion $f: A \rightarrow \mathbb{R_+}$ dar, die jeder Kante $a \in A(G)$ einen nichtnegativen Flusswert $f(a) \in \mathbb{R_+}$ zuweist. Des weiteren muss folgende Bedingung erfüllt sein, damit es sich bei dieser Funktion um einen Fluss handelt. Dafür muss gelten, dass der Flusswert einer Kante $a \in A(G)$ höchstens so groß ist, wie die Kapazität der Kante mit: \footnote{TODO: Quelle, Netzwerk noch erklären} $$\forall a \in A(G): f(a) \leq u(a)$$
\end{definition}

Mithilfe der Idee einer Flussfunktion in einem Graphen können die Kanten und die Beziehungen zwischen den einzelnen Services genauer dargestellt werden. Die Gewichtung der Kanten kann eine Repräsentation der Intensität der Nutzung dieser Kante darstellen.

Die mathematische Idee eines Graphen oder einem daraus resultierenden Netzwerk können gut

\begin{itemize}
	\item Eine Idee von Elastic vorstellen $\Rightarrow$ APM zusammen mit ML-Nodes können zur Anomaly-Detection und Predicitve Maintance genutzt werden. Lösen die das eigentliche Problem, wenn ja in welchem Ausmaß
	\item Kurze Einführung in Graphdatenbanken, im speziellen Neo4J. Wieso passen die so gut? referenzieren auf Bilder und \enquote{Abhängigkeiten} Wie kann damit eine Lösung konstruiert werden?
	\begin{itemize}
		\item Statischer Ansatz $\Rightarrow$ von den Entwicklern definierte Abhängigkeiten werden in der Service-Definition angegeben. Der Graph kann aus diesen SD's erstellt werden. Hier gibt es Probleme: Manuelle Veranwtortlichkeit widerspricht eigentlicher Idee von Risikoeinschätzung, da ein neuer Fehler Mensch eingebaut wird.
		\item Automatischer Nutzungsbasierter, somit dynamischer Aufbau des Graphen. Prinzip ähnlich wie bei Prometheus (populäres Tool zum sammeln von Metriken). Konzept ähnlich wie Distributed Tracing. Dort werden alle Traces mit ihren Spans zusammengefasst und zentral ausgewertet. Kombination aus dieser Idee mit Prometheus-Ansatz sieht dann folgendermaßen aus:
		
		Jeder Service exposed einen \texttt{/traffic}-Endpoint der unstrukturierte Daten bzgl. der Netzwerkaktivität enthält. Diese können dann in einem Service der für den Aufbau des Graphen zuständig ist zu ebendiesem umgewandelt werden.
		\item Es kann zusätzlich überlegt werden, ob anstatt dieses \texttt{PULL}-Verfahrens eine Push Variante gewählt wird, welche ähnlich wie \texttt{fluentd} als Sidecar in einer Containererisierten Umgebung läuft. Die könnte dann periodisch die Netzwerkdaten pushen, wenn sie Zugriff darauf hat.
	\end{itemize}
	\item Es kann überlegt werden welche Metadaten zusätzlich im Rahmen dieses Graphen eine sinnvolle Ergänzugn bieten würden, sodass ein weiterer Mehrwert geschaffen werden kann. (Ist das noch im Rahmen der Arbeit? Kommt das eher in den Ausbilck mit ein paar Ideen?)
	\item Wie können jetzt die Sachen in dem coolen Graphen genutzt werden?
	\begin{itemize}
		\item Kurze \texttt{CYPHER-QUERIES} Aufschreiben:
		\begin{itemize}
			\item Wie finde ich affectete services raus
			\item was passiert wenn ein Service X ausfällt
			\item Was ist die Zentralste Komponente in meinem Unternehmen
			\item usw.
		\end{itemize}
	\end{itemize}
\end{itemize}

\chapter{Bewertung und Einschätzung der Arbeit, sowie Ausbilck auf künfitge Arbeiten}
%	Literaturverzeichnis
\clearpage
\ihead{}
\printbibliography[title=Literaturverzeichnis]
\cleardoublepage

% Der Anhang beginnt hier - jedes Kapitel wird alphabetisch aufgezählt. (Anhang A, B usw.)
% \appendix
% \ihead{\appendixname~\thechapter} % Neue Header-Definition

% Ehrenwörtliche Erklärung ewerkl.tex einziehen
\input{ewerkl.tex}


\end{document}
